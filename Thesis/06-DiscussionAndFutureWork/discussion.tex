\chapter{Discussion and Future Work}
\label{chap:disc}
\section*{Chapter Outline}
In this chapter we analyse and discuss the results presented in the previous section. We discuss the near-constant discrepancy between the estimated mutual delay and the ground-truth, and propose explanations for the low correlation in the mutual information investigation. We then compare the various cell-classifiers, discussing the difference between the algorithms' performance and the ability for the classifier to reconstruct a 4-leaf star topology. We also discuss areas that future research could investigate to improve on our findings. 


\section{Link-Level Analysis}
\subsection{Delay Estimation}


% TODO: Delay usually a bit high because the "actual" delay is from the netcon, not the netcon + synapse. Also measuring the cells output, not the cells input. The fact that there's a clear peak in the correlation for nearly every simulation with the estimate being nearly a constant overshoot shows that its measuring some form of delay, more like the propagation delay. Delays of 0ms were removed because error value. Delay fits well with a clear linear correlation between the actual delay and the estimate.\\
% TODO: Future work here could be on taking more than just the NetCon delay into account when getting the ground truth delay.

The delay estimation has proven to be quite accurate considering the relatively simple concept it is based on. While the estimated delay tends to be higher than the actual delay, the proportional difference between the two seems to be relatively constant meaning that a clear correlation can be seen, and that a simple linear model can fit with a decent R-squared score. This nearly constant difference between the estimation and the actual value can be explained by the nature of the simulation; the "ground truth" value taken as the network delay is the corresponding parameter applied to the \emph{NetCon} object connecting the two cells, while the measurements we take come from the soma of the two cells. This means that any delay we observe is from the delay of signal propagation through the axom of the presynaptic cell, through the NetCon object, across the synapse, and then through the dendrites of the post-synaptic cell. This means that any observed delay would be higher than the delay of just the NetCon object, which is supported by our data.\\
Another point of consideration in the delay estimation is that the estimator was not always able to predict a delay. This in general is due to the lack of peaks in the cross-correlation, which in turn may be caused by a lack of spikes in one or both of the voltage measurements possibly caused by a lack of synaptic connections. In these cases, the estimator returns a delay of 0ms. For this reason, any estimations of 0ms delay were simply removed from the dataset as they were assumed to have been caused by an invalid simulation.
\par
Future work in this area could take the whole delay path into account when forming the ground truth in the simulated network to verify the hypothesis that the estimation discrepancy is caused by this inaccurate ground truth. On top of this, the current model is quite simple in design and so could be improved upon to increase the robustness of the estimator to edge-cases where simple cross-correlation is not sufficiently accurate.

\subsection{Mutual Information}
% TODO: Discuss the results and how our analysis of the mutual information suggests this model isn't applicable to neurons.\\
% TODO: bad results due to lack enough data? Cite the paper that suggested this in their own study of the mutual information.\\
% TODO: Future work -> Discuss other models that may be applicable (i.e. the complex theoretical models given in other papers)\\

While the distribution of the measured mutual information in the simulation dataset does tend to follow a normal-like fit, it is clear from the various scatter plots that there is no correlation between the various link-level parameters between the cells and the discrete-memoryless model applied to the discretised spike trains. This lack of correlation is confirmed by the linear model which was "fit" to each of the link parameters, indicating a very low correlation with an R-squared score of only 0.03. This suggests that the application of the information model commonly used in digital systems is not sufficient to describe the information carried between cells through synaptic connections, possibly due to the fact that the transmission of a signal between two neurons is not entirely memoryless as the synapse has a refactory period during neurotransmitter reuptake. This could also be explained by a lack of sample data, as previous work done in this area has suggested that the accurate prediction of the entropy and mutual information of these links relies heavily on the size of the dataset, in particular of the length of the simulation and the number of spikes observed \cite{spikeTrainInfo}. As a result of this, future work in this area could investigate the effect of the simulation length and the activity within the simulation on the correlation between the calculated mutual information and the link parameters.\\
As well as this, other models could be applied in this domain to find the above parameter-information effect; for example, the calculation of upper and lower bounds on the mutual information as well as different approaches to the conversion between measured spike-trains and symbol sequences could be applied \cite{spikeTrainInfo}.

\section{Classification}
%TODO: Filter size discussion
%TODO: Classifier tweaking didnt change much -> could indicate we're at the limit of what the filter coeffs can tell us.
%TODO: Discuss the relatively good results and the differences between classifiers.\\
%TODO: Decision tree doing better than random forest? Possibly due to overfitting.
%TODO: Comment on our metrics, and why more metrics might be suitable.\\
%TODO: Discuss the better classification results between layers -> l1 v l6 etc\\
%TODO: Discuss the ability for the classifiers to identify layers vs m-types vs e-types.\\
%TODO: Good prediction for whole-cell -> might mean that predicting one correctly increases chance of predicting the other 2. Chaining effect?
%TODO: Good at classifying "similar" classes i.e UTPC classified as TPC, might be improved by better features.
%TODO: Accuract doesn't take probabilty into account.
%TODO: More m-types/etypes here than in list



The classification of cell types from measured membrane potential has shown promising results, with relatively high accuracy considering the high number of classes to which the models were estimating. Evidently, the SVM-based classifier had the highest level of accuracy, with the artificial neural network being close behind in performance. This was surprising, as neural networks are widely used for high-order classification problems. It is possible, however, that the close level of accuracy between the two is indicative of the limit of the features on which we are predicting and that the level of information that the features hold does not allow for accuracy above this level. This is supported by the fact that tweaks to the classifiers' parameters (i.e. kernel size in SVMs and hidden-layer size in the neural networks) did not have any noticeable effect on the accuracy, indicating that they are close to maximising the classification based on these features. Future work in this area could therefore look at the extension of the feature-space. For example, while we based the feature extraction on the characterisation of a cell from the LNP cascade model, we ignored the nonlinear transformation component. Taking this component into account could improve the accuracy of the classifiers. Another consideration to be made here is the size of the linear filter used as the characteristic features (the order of the FIR filter). A number of different filter sizes were investigated, however we found that above about 64 coefficients, the accuracy did not improve. This again indicates the limit of this feature set, which is supported by the plots of the impulse response of some of the estimated filters in Figure \ref{fig:sampImpRes}. Here we can see that the majority of the characterisation between cell types is in the central coefficients, with reduced variance as we move away from the 0-point. Increasing the order of the filter will only add detail to the two extremes of this impulse response, which adds features that seem to bare little characterising information.
\par
As mentioned previously, the accuracy metric chosen to compare the classifiers does not fully indicate the performance of the model. When dealing with this form of classifier, a confusion matrix and associated class-recall and class-precision metrics can give a much more informative idea of the efficacy of the estimator. In this case, however, the amount of individual values that would need to be compared between the three sub-groups (each with varying amounts of classes) and the 4 classification algorithms makes it unfeasible to directly compare the models in this way. With that in mind, it was found that the class recall and class precision were quite similar between the 4 classification algorithms meaning that directly comparing the accuracy of the models can give a good idea of the comparative performance.\\
Another consideration here is with the "factor improvement" metric, taken as the proportion improvement of the model's accuracy versus the equivalent accuracy of randomly guessing with the class-space. The equivalent accuracy of random guessing assumes that the distribution of the classes amongst the dataset is equal, i.e. the probability of one class occurring is no higher than any other class. While this is true for the layer-group (since the dataset was constructed ensuring an equal proportion of each of the layers) it is not necessarily true for the m-type and e-type classes as some of these groups are more likely to occur than others. On top of this, the number of possible classes for the "whole-cell" type classification was taken to be the product of the number of layers, m-types, and e-types. This does not take into account that some permutations of these groups do not occur in the dataset (however they may occur in practice), and so the actual factor improvement may be lower than observed. With this in mind, however, it is worth noting that the distributions of these classes are not significantly skewed in any single direction, and so while not fully indicative of the performance, the factor improvement does show the general trend of the estimators.\\
It is also evident that the number of classes on which we predict for the m-type and e-type groups exceeds those in the corresponding lists found in \ref{tab:m-type_table} and \ref{tab:e-type_table}. This is due to the sub-class variations within the dataset such as cADpyr230 and cADpyr231 within the cADpyr e-type group. 
\par
Keeping these considerations in mind, it is clear that the classifiers show a positive trend in cell-type estimation. In all cases, the decision tree classifier performed better than the random forest classifier, which is surprising as the random forest algorithm is a variation of the decision tree algorithm which should have higher performance. This could be explained by the fact that decision tree classifiers tend to overfit to the dataset, which might result in higher training accuracies.\\
The classifier with the highest performance in all cases was the SVM-based model. In classifying the layer type, the SVM model was capable of achieving 62.5\% accuracy, a factor improvement of 3.13 over random guessing. By looking at the confusion matrix for this classifier in figure \ref{fig:svmConfMatLayer}, we can see that the classifier has very good performance in classifying between layer 1 and layer 6 with close to 100\% accuracy between these classes where only 1\% of layer 6 cells were predicted as layer 1, and less than 1\% of layer 1 cells were predicted as layer 6. The overall accuracy decreases as the intermediate layers are added, with the worst performing component being incorrectly predicting a layer 4 cell as layer 5 21\% of the time. It is evident, therefore, that the highest degree of separation using the FIR-filter estimation is between layer 1 and layer 6.

\par

In the reconstruction of the 4-leaf topology through endpoint measurements using the trained SVM classifier, the individual sub-group accuracies tend to reflect those of the 2-cell networks with a layer-estimation accuracy of 61.82\%, an m-type accuracy of 56.34\%, and an e-type accuracy of 64.62\% representing a factor improvement of 3.09, 14.09, and 9.05 respectively. The interesting result in this investigation, however, is the whole-cell estimation (where each of the individual sub-group estimators were correct) with an overall accuracy of 36.23\% and a factor improvement of 634.5. As well as this, looking at the sample reconstruction in Figure \ref{fig:4CellRecon}, it is clear that the classification model is not always correct, however incorrect estimations are often with very similar classes such as where the UTPC m-type is estimated as a TPC m-type.

\par

There are a number of areas that could be worked on in future to extend the investigation of this domain. For example, to estimate the equivalent FIR filter we use both the input and the output voltage measurements, however the response of a cell is really effected only by signal impulses. Therefore, it may not be required to use the input spike train at all. Instead, the input impulse train could be estimated from the output spike train (i.e. areas where a series of spikes start could be where the cell received an impulse), and the equivalent impulse response could be determined from this. In this way, only the output of the cell would need to be measured. This would also help with the classification of more complex networks where the proportional number of measurements versus the number of cells is greatly reduced.\\
Another point that could be investigated in future work is in the variation of the central/stimulus cell. Throughout the production of our simulation database, the presynaptic cell was kept constant to minimise variables. In practice however, many different cell types may interconnect and so the ability to classify a cell regardless of the presynaptic cell type is important. Conceptually, the performance should be relatively similar as the features used in the classifiers is based on the impulse response of the postsynaptic cell, rather than the characteristics of the presynaptic cell.\\
Finally, another point of consideration for future work is in multi-path networks. In this investigation we dealt solely with single path (one cell to one cell) connections. In practice, a given cell may be stimulated by a number of presynaptic cells. This can be characterised using the LNP model by using multiple linear filters, and computing the output based on a combination of the individual coefficients \cite{lnp}. Similarly, in our study we used only excitatory synaptic connections to generate measurements with a large number of characterising spikes. Future work could therefore look at the classification of cells based on various combinations of excitatory to inhibitory connections.
